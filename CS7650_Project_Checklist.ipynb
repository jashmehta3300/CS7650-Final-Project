{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "zL7kAFOGDqsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBta5OdWod6c",
        "outputId": "5ed46e84-c2e7-4d90-b300-de2e33f6e115"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: checklist in /usr/local/lib/python3.9/dist-packages (0.0.11)\n",
            "Requirement already satisfied: spacy>=2.2 in /usr/local/lib/python3.9/dist-packages (from checklist) (3.5.2)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.9/dist-packages (from checklist) (0.3.6)\n",
            "Requirement already satisfied: ipywidgets>=7.5 in /usr/local/lib/python3.9/dist-packages (from checklist) (7.7.1)\n",
            "Requirement already satisfied: patternfork-nosql in /usr/local/lib/python3.9/dist-packages (from checklist) (3.6)\n",
            "Requirement already satisfied: iso-639 in /usr/local/lib/python3.9/dist-packages (from checklist) (0.4.5)\n",
            "Requirement already satisfied: munch>=2.5 in /usr/local/lib/python3.9/dist-packages (from checklist) (2.5.0)\n",
            "Requirement already satisfied: transformers>=2.8 in /usr/local/lib/python3.9/dist-packages (from checklist) (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.9/dist-packages (from checklist) (1.22.4)\n",
            "Requirement already satisfied: jupyter>=1.0 in /usr/local/lib/python3.9/dist-packages (from checklist) (1.0.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (5.7.1)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (7.34.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (5.5.6)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (3.6.4)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.5->checklist) (3.0.7)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist) (6.4.8)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist) (6.1.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist) (5.4.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from jupyter>=1.0->checklist) (6.5.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from munch>=2.5->checklist) (1.16.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (1.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (23.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (2.4.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (3.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (4.65.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (1.10.7)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (3.0.12)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (0.10.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (2.27.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (6.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (8.1.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (3.1.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (0.7.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (67.7.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy>=2.2->checklist) (1.1.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.8->checklist) (0.13.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.8->checklist) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.8->checklist) (0.14.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=2.8->checklist) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=2.8->checklist) (3.12.0)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (6.0.10)\n",
            "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (20221105)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (1.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (0.18.3)\n",
            "Requirement already satisfied: cherrypy in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (18.8.0)\n",
            "Requirement already satisfied: backports.csv in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (1.0.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (3.8.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (0.8.11)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (4.11.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from patternfork-nosql->checklist) (4.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.8->checklist) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=2.8->checklist) (2023.4.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (6.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (2.14.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (4.4.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.18.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (3.0.38)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2->checklist) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2->checklist) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.2->checklist) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy>=2.2->checklist) (8.1.3)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (0.17.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (21.3.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (1.5.6)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (5.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (0.16.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (5.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook->jupyter>=1.0->checklist) (23.2.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->patternfork-nosql->checklist) (2.4.1)\n",
            "Requirement already satisfied: cheroot>=8.2.1 in /usr/local/lib/python3.9/dist-packages (from cherrypy->patternfork-nosql->checklist) (9.0.0)\n",
            "Requirement already satisfied: portend>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from cherrypy->patternfork-nosql->checklist) (3.1.0)\n",
            "Requirement already satisfied: jaraco.collections in /usr/local/lib/python3.9/dist-packages (from cherrypy->patternfork-nosql->checklist) (4.1.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from cherrypy->patternfork-nosql->checklist) (9.1.0)\n",
            "Requirement already satisfied: zc.lockfile in /usr/local/lib/python3.9/dist-packages (from cherrypy->patternfork-nosql->checklist) (3.0.post1)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/dist-packages (from feedparser->patternfork-nosql->checklist) (1.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy>=2.2->checklist) (2.1.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (6.0.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.2.1)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.1)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.7.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (1.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.2.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->jupyter>=1.0->checklist) (0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk->patternfork-nosql->checklist) (1.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.9/dist-packages (from pdfminer.six->patternfork-nosql->checklist) (40.0.2)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from qtconsole->jupyter>=1.0->checklist) (2.3.1)\n",
            "Requirement already satisfied: jaraco.functools in /usr/local/lib/python3.9/dist-packages (from cheroot>=8.2.1->cherrypy->patternfork-nosql->checklist) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/dist-packages (from cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (1.15.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.9/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets>=7.5->checklist) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook->jupyter>=1.0->checklist) (3.2.0)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook->jupyter>=1.0->checklist) (4.3.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.7.0)\n",
            "Requirement already satisfied: tempora>=1.8 in /usr/local/lib/python3.9/dist-packages (from portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (5.2.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5->checklist) (0.2.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook->jupyter>=1.0->checklist) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->jupyter>=1.0->checklist) (0.5.1)\n",
            "Requirement already satisfied: jaraco.text in /usr/local/lib/python3.9/dist-packages (from jaraco.collections->cherrypy->patternfork-nosql->checklist) (3.11.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->patternfork-nosql->checklist) (2.21)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter>=1.0->checklist) (23.1.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->patternfork-nosql->checklist) (2022.7.1)\n",
            "Requirement already satisfied: autocommand in /usr/local/lib/python3.9/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (2.2.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.9/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (6.0.4)\n",
            "Requirement already satisfied: jaraco.context>=4.1 in /usr/local/lib/python3.9/dist-packages (from jaraco.text->jaraco.collections->cherrypy->patternfork-nosql->checklist) (4.3.0)\n",
            "2023-04-27 16:45:09.856746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-27 16:45:11.432436: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-27 16:45:13.554232: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-27 16:45:13.554851: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-04-27 16:45:13.555078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install checklist\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "QR5w3QuoD6Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import torch\n",
        "import sys\n",
        "import numpy as np\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "import pandas as pd\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "import checklist\n",
        "from checklist.editor import Editor\n",
        "from checklist.perturb import Perturb\n",
        "from checklist.test_types import MFT, INV, DIR\n",
        "from checklist.test_suite import TestSuite\n",
        "from checklist.expect import Expect\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "O60cgXunD5sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mount Drive"
      ],
      "metadata": {
        "id": "pM_i4yLNEY-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P14bJIlqpVEW",
        "outputId": "ca2cae13-54fa-45f5-ad74-5b7ef5d1cde8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Testset"
      ],
      "metadata": {
        "id": "FDlOuIIqEdaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('drive/MyDrive/nlp_project/datasets/senti_test.csv')\n",
        "data = list(nlp.pipe(dataset['text']))\n",
        "data[0:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTEIDWdIEczB",
        "outputId": "0ea97ba1-72b4-40ab-9c4d-3fd9c2a24bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.,\n",
              " Reading my kindle2...  Love it... Lee childs is good read.,\n",
              " Ok, first assesment of the #kindle2 ...it fucking rocks!!!,\n",
              " @kenburbary You'll love your Kindle2. I've had mine for a few months and never looked back. The new big one is huge! No need for remorse! :),\n",
              " @mikefish  Fair enough. But i have the Kindle2 and I think it's perfect  :)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "8sWDXMTQE0KA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Centralized BERT"
      ],
      "metadata": {
        "id": "Y0tdMZ7tE3dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"drive/MyDrive/nlp_project/models/centralized_bert/\",local_files_only=True)\n",
        "pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)"
      ],
      "metadata": {
        "id": "H7Su7DdxEzvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Federated BERT"
      ],
      "metadata": {
        "id": "ZxSZKByNgpga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"drive/MyDrive/nlp_project/models/federated_bert/\",local_files_only=True)\n",
        "federated_pipe = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0)"
      ],
      "metadata": {
        "id": "n5iYPWEsgn8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checklist"
      ],
      "metadata": {
        "id": "_-4p2FZ8FCV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "suite = TestSuite()\n",
        "editor = Editor()"
      ],
      "metadata": {
        "id": "THj_48Bcp49U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Minimum Functionality Test (MFT) - Negation"
      ],
      "metadata": {
        "id": "iR0vrAlBF0P7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "', '.join(editor.suggest('This is not {a:mask} {thing}.', thing=['book', 'movie', 'show', 'game'])[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "TWLCFd9HF3AM",
        "outputId": "8e41a564-7c79-49a6-bac6-8fcea249608f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'easy, academic, ordinary, educational, average, enjoyable, entertaining, interesting, old, independent, good, art, exciting, original, ideal, innocent, excellent, adventure, amateur, awards, actual, introductory, engaging, obscure, amazing, bad, experimental, accessible, awful, great'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = ['good', 'enjoyable', 'exciting', 'excellent', 'amazing', 'great', 'engaging']\n",
        "neg = ['bad', 'terrible', 'awful', 'horrible']"
      ],
      "metadata": {
        "id": "PvfLulrVFr59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = editor.template('This is not {a:pos} {mask}.', pos=pos, labels=0, save=True, nsamples=200)\n",
        "ret += editor.template('This is not {a:neg} {mask}.', neg=neg, labels=1, save=True, nsamples=200)"
      ],
      "metadata": {
        "id": "_ynUGj8wp72X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ret.data[0])\n",
        "print(ret.data[201])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVdE2n9KHQIp",
        "outputId": "4005ac33-72a3-44d6-f38d-78b1ceebc6d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is not an amazing option.\n",
            "This is not a terrible analogy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = MFT(ret.data, labels=ret.labels, name='Simple negation',\n",
        "           capability='Negation', description='Very simple negations.')"
      ],
      "metadata": {
        "id": "ju1YYyXgp_lO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test, 'simple negations: negative', 'Negation', 'Very simple negations of positive statements')"
      ],
      "metadata": {
        "id": "I2olnsCjHsSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Invariance tests"
      ],
      "metadata": {
        "id": "CCtyHkb8Hvzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Perturbing Names"
      ],
      "metadata": {
        "id": "DDXd2JNDOsrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(data, Perturb.change_names)\n",
        "test = INV(**t,name='Perturbing Names',capability='Robustness')"
      ],
      "metadata": {
        "id": "YsUiz7wDHvaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjLDAMuIIf9-",
        "outputId": "4b64e208-1d98-41c5-ab34-8ca7a97dd6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Reading my kindle2...  Love it... Lee childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Charles childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Juan childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Thomas childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Julian childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Stephen childs is good read.',\n",
              " 'Reading my kindle2...  Love it... David childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Isaac childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Jason childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Jeffrey childs is good read.',\n",
              " 'Reading my kindle2...  Love it... Nathaniel childs is good read.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Perturbing Names','Robustness','changing names')"
      ],
      "metadata": {
        "id": "n64gYAnJIk8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ret = editor.template('{male} reads kindle. He likes to read.... loves it!', labels=1, save=True, nsamples=200)\n",
        "ret += editor.template('{female} reads kindle. She likes to read.... loves it!', labels=1, save=True, nsamples=200)\n",
        "ret += editor.template('{female1} reads kindle. {female2} likes to read.... loves it!', labels=1, save=True, nsamples=200)\n",
        "ret += editor.template('{female1} reads kindle. {female2} hates to read.', labels=0, save=True, nsamples=200)"
      ],
      "metadata": {
        "id": "o5QsIV6qeGwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(list(nlp.pipe(list(ret.data))), Perturb.change_names)\n",
        "test = INV(**t,name='Perturbing Additional Names',capability='Robustness')"
      ],
      "metadata": {
        "id": "OMMwejXNgGE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpqAEKC-iUli",
        "outputId": "32d92fbe-a847-4a81-fa71-1a4b91d39a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jack reads kindle. He likes to read.... loves it!',\n",
              " 'Alex reads kindle. He likes to read.... loves it!',\n",
              " 'Henry reads kindle. He likes to read.... loves it!',\n",
              " 'Jordan reads kindle. He likes to read.... loves it!',\n",
              " 'Joshua reads kindle. He likes to read.... loves it!',\n",
              " 'Lucas reads kindle. He likes to read.... loves it!',\n",
              " 'Connor reads kindle. He likes to read.... loves it!',\n",
              " 'Austin reads kindle. He likes to read.... loves it!',\n",
              " 'Isaac reads kindle. He likes to read.... loves it!',\n",
              " 'Jack reads kindle. He likes to read.... loves it!',\n",
              " 'Jason reads kindle. He likes to read.... loves it!']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Perturbing Additional Names','Robustness','changing more names')"
      ],
      "metadata": {
        "id": "z23jC-sSinwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Perturbing Locations"
      ],
      "metadata": {
        "id": "G9B7ZhdmXdIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(data, Perturb.change_location)\n",
        "test = INV(**t,name='Perturbing Locations',capability='Robustness')"
      ],
      "metadata": {
        "id": "TPIv2nk3XcpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IChqQ2LZi1eZ",
        "outputId": "3d276483-6dfe-46f7-d9d4-a38deac5083f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in San Francisco wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in New York wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Gilbert wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in New Orleans wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Nashville-Davidson wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Bakersfield wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Fremont wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Winston-Salem wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Lincoln wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Albuquerque wtf\",\n",
              " \"glad i didnt do Bay to Breakers today, it's 1000 freaking degrees in Charlotte wtf\"]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Perturbing Locations','Robustness','changing locations')"
      ],
      "metadata": {
        "id": "KA9Yg9qnjAlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Adding Typos"
      ],
      "metadata": {
        "id": "-sVwY61LUPMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(dataset['text'], Perturb.add_typos)\n",
        "test = INV(**t,name='Add Typos',capability='Robustness')"
      ],
      "metadata": {
        "id": "3N4TmjBqJER4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrt0oZxiJMQD",
        "outputId": "78d06aa9-1483-4aea-a54b-73faef1d3848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
              " '@stellargirl I loooooooovvvvvveee my Kidnle2. Not that the DX is cool, but the 2 is fantastic in its own right.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Add Typos','Robustness','adding typos')"
      ],
      "metadata": {
        "id": "-wsNp-zeKCS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(dataset['text'], Perturb.add_typos,typos=2)\n",
        "test = INV(**t,name='Add 2 Typos',capability='Robustness')"
      ],
      "metadata": {
        "id": "MoQ15iWvUo3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMyGUGX5UxKJ",
        "outputId": "eaa7ebca-0b12-43ca-f9b4-4a099d63e86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
              " '@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantsatic in its ownr ight.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Add 2 Typos','Robustness','adding 2 typos')"
      ],
      "metadata": {
        "id": "tR6_iWFHUyJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Punctuation"
      ],
      "metadata": {
        "id": "zWHPda3qUbiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(data, Perturb.punctuation)\n",
        "test = INV(**t,name='Punctuation',capability='Robustness')"
      ],
      "metadata": {
        "id": "HKwLfpTYUgYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qJmlAChVEQu",
        "outputId": "c0a0cb83-55f3-4a26-e604-54de6645eaf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right.',\n",
              "  '@stellargirl I loooooooovvvvvveee my Kindle2. Not that the DX is cool, but the 2 is fantastic in its own right'],\n",
              " ['Reading my kindle2...  Love it... Lee childs is good read.',\n",
              "  'Reading my kindle2...  Love it... Lee childs is good read']]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test,'Punctuation','Robustness','strip and / or add punctuation')"
      ],
      "metadata": {
        "id": "Sd5nEHDMVHNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Contractions"
      ],
      "metadata": {
        "id": "1Qk5YWnmVR7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = Perturb.perturb(dataset['text'], Perturb.contractions)\n",
        "test = INV(t.data)"
      ],
      "metadata": {
        "id": "9xbekWuYVUsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t.data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOhu4t7iVlYC",
        "outputId": "1308eedf-2007-4cee-c70d-9b5dd3ac31d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"@kenburbary You'll love your Kindle2. I've had mine for a few months and never looked back. The new big one is huge! No need for remorse! :)\",\n",
              " '@kenburbary You will love your Kindle2. I have had mine for a few months and never looked back. The new big one is huge! No need for remorse! :)']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.add(test, 'Contractions', 'Robustness', 'Contract or expand contractions, e.g. What is -> What\\'s')"
      ],
      "metadata": {
        "id": "74gfFZK3VnSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running Tests"
      ],
      "metadata": {
        "id": "O2ceIzHNjHoz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Centralized BERT"
      ],
      "metadata": {
        "id": "tN1ufH8kjQ9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = pipe(data)\n",
        "    preds = np.array([ 0 if p[\"label\"]==\"negative\" else 1 for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if p[\"label\"]==\"negative\" else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "-T5czazfqaVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_conf(['good','bad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkvNZIhTsJFz",
        "outputId": "c78518e1-6009-4c59-c4fe-4444610241bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 0]),\n",
              " array([[0.09076554, 0.90923446],\n",
              "        [0.9978283 , 0.0021717 ]]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtv8nCBKssha",
        "outputId": "bef53fc6-6fd6-468b-9c3b-7e8636886667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running simple negations: negative\n",
            "Predicting 400 examples\n",
            "Running Perturbing Names\n",
            "Predicting 374 examples\n",
            "Running Perturbing Additional Names\n",
            "Predicting 6985 examples\n",
            "Running Perturbing Locations\n",
            "Predicting 308 examples\n",
            "Running Add Typos\n",
            "Predicting 996 examples\n",
            "Running Add 2 Typos\n",
            "Predicting 996 examples\n",
            "Running Punctuation\n",
            "Predicting 1152 examples\n",
            "Running Contractions\n",
            "Predicting 210 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHXYta1gs0eB",
        "outputId": "944a79a5-ea1f-4bf5-c8c6-aabb2b0e721a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robustness\n",
            "\n",
            "Perturbing Names\n",
            "Test cases:      34\n",
            "Fails (rate):    1 (2.9%)\n",
            "\n",
            "Example fails:\n",
            "0.1 Lawson to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "1.0 Jesus to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "0.6 Nathaniel to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Perturbing Additional Names\n",
            "Test cases:      635\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Perturbing Locations\n",
            "Test cases:      28\n",
            "Fails (rate):    6 (21.4%)\n",
            "\n",
            "Example fails:\n",
            "0.2 myfoxdc Barrie Students Back from Trip to China: A Silver Spring high school's class trip to China has en.. http://tinyurl.com/nlhqba\n",
            "0.8 myfoxdc Barrie Students Back from Trip to Ethiopia: A Silver Spring high school's class trip to Ethiopia has en.. http://tinyurl.com/nlhqba\n",
            "0.7 myfoxdc Barrie Students Back from Trip to Sudan: A Silver Spring high school's class trip to Sudan has en.. http://tinyurl.com/nlhqba\n",
            "\n",
            "----\n",
            "0.8 Trouble in Iran, I see. Hmm. Iran. Iran so far away. #flockofseagullsweregeopoliticallycorrect\n",
            "0.0 Trouble in United States, I see. Hmm. United States. United States so far away. #flockofseagullsweregeopoliticallycorrect\n",
            "0.0 Trouble in Saudi Arabia, I see. Hmm. Saudi Arabia. Saudi Arabia so far away. #flockofseagullsweregeopoliticallycorrect\n",
            "\n",
            "----\n",
            "0.7 Rocawear Heads to China, Building 300 Stores  - http://tinyurl.com/nofet3\n",
            "0.5 Rocawear Heads to United Kingdom, Building 300 Stores  - http://tinyurl.com/nofet3\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Add Typos\n",
            "Test cases:      498\n",
            "Fails (rate):    39 (7.8%)\n",
            "\n",
            "Example fails:\n",
            "0.5 Found a safeway. Picking up a few staples.\n",
            "0.0 Found a safeway. Pikcing up a few staples.\n",
            "\n",
            "----\n",
            "1.0 Went to see the Star Trek movie last night.  Very satisfying.\n",
            "0.2 Went to see the Star Trek movie last night.  Ver ysatisfying.\n",
            "\n",
            "----\n",
            "0.2 @cwong08 I have a Kindle2 (&amp; Sony PRS-500). Like it! Physical device feels good. Font is nice. Pg turns are snappy enuf. UI a little klunky.\n",
            "0.6 @cwong08 I have a Kindle2 (&amp; Sony PRS-500). Like it! Physical edvice feels good. Font is nice. Pg turns are snappy enuf. UI a little klunky.\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Add 2 Typos\n",
            "Test cases:      498\n",
            "Fails (rate):    59 (11.8%)\n",
            "\n",
            "Example fails:\n",
            "1.0 New blog post: Nike Trainer 1 http://bit.ly/394bp\n",
            "0.4 New blog pots: Nike Trainer 1h ttp://bit.ly/394bp\n",
            "\n",
            "----\n",
            "0.0 good news, just had a call from the Visa office, saying everything is fine.....what a relief! I am sick of scams out there! Stealing!\n",
            "1.0 good news, just had  acall from the Visa office, saying everything is fine.....what a relief! I am sick of scams out there! Stealign!\n",
            "\n",
            "----\n",
            "1.0 I hope the girl at work  buys my Kindle2\n",
            "0.0 I hope the girl at work  busy my Kindl2e\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Punctuation\n",
            "Test cases:      498\n",
            "Fails (rate):    25 (5.0%)\n",
            "\n",
            "Example fails:\n",
            "0.4 is going to sleep then on a bike ride:]\n",
            "0.9 is going to sleep then on a bike ride.\n",
            "0.8 is going to sleep then on a bike ride\n",
            "\n",
            "----\n",
            "0.3 @Iheartseverus we love you too and don't want you to die!!!!!!  Latex = the devil\n",
            "1.0 @Iheartseverus we love you too and don't want you to die!!!!!!  Latex = the devil.\n",
            "\n",
            "----\n",
            "0.5 I spent most of my day reading a jQuery book. Now to start drinking some delirium tremens.\n",
            "1.0 I spent most of my day reading a jQuery book. Now to start drinking some delirium tremens\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Contractions\n",
            "Test cases:      103\n",
            "Fails (rate):    1 (1.0%)\n",
            "\n",
            "Example fails:\n",
            "0.5 I Will NEVER Buy a Government Motors Vehicle: Until just recently, I drove GM cars. Since 1988, when I bought a .. http://tinyurl.com/lulsw8\n",
            "0.8 I'll NEVER Buy a Government Motors Vehicle: Until just recently, I drove GM cars. Since 1988, when I bought a .. http://tinyurl.com/lulsw8\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Negation\n",
            "\n",
            "simple negations: negative\n",
            "Test cases:      400\n",
            "Fails (rate):    40 (10.0%)\n",
            "\n",
            "Example fails:\n",
            "0.1 This is not a bad diagnosis.\n",
            "----\n",
            "0.1 This is not a horrible diagnosis.\n",
            "----\n",
            "0.2 This is not an awful film.\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Federated BERT"
      ],
      "metadata": {
        "id": "rEIJBRjMjXh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_conf(data):\n",
        "    raw_preds = federated_pipe(data)\n",
        "    preds = np.array([ 0 if p[\"label\"]==\"negative\" else 1 for p in raw_preds])\n",
        "    pp = np.array([[p[\"score\"], 1-p[\"score\"]] if p[\"label\"]==\"negative\" else [1-p[\"score\"], p[\"score\"]] for p in raw_preds])\n",
        "    return preds, pp"
      ],
      "metadata": {
        "id": "pTHXpupgjZ5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_and_conf(['good','bad'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ0AYHQRjdnD",
        "outputId": "645b30a8-0fe4-43f0-bc71-ccae03d22049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 0]),\n",
              " array([[0.1482026 , 0.8517974 ],\n",
              "        [0.99288392, 0.00711608]]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.run(pred_and_conf,overwrite=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeXi6K-Sjlay",
        "outputId": "8a4539f4-208e-4b8c-8a6a-55b6ba52a126"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running simple negations: negative\n",
            "Predicting 400 examples\n",
            "Running Perturbing Names\n",
            "Predicting 374 examples\n",
            "Running Perturbing Additional Names\n",
            "Predicting 6985 examples\n",
            "Running Perturbing Locations\n",
            "Predicting 308 examples\n",
            "Running Add Typos\n",
            "Predicting 996 examples\n",
            "Running Add 2 Typos\n",
            "Predicting 996 examples\n",
            "Running Punctuation\n",
            "Predicting 1152 examples\n",
            "Running Contractions\n",
            "Predicting 210 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "suite.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIilnFysjp4n",
        "outputId": "8fadbc1d-3989-4350-bee2-cf2bbc1588d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robustness\n",
            "\n",
            "Perturbing Names\n",
            "Test cases:      34\n",
            "Fails (rate):    1 (2.9%)\n",
            "\n",
            "Example fails:\n",
            "0.4 Lawson to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "0.9 Jesus to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "0.6 Timothy to head Newedge Hong Kong http://bit.ly/xLQSD #business #china\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Perturbing Additional Names\n",
            "Test cases:      635\n",
            "Fails (rate):    0 (0.0%)\n",
            "\n",
            "\n",
            "Perturbing Locations\n",
            "Test cases:      28\n",
            "Fails (rate):    5 (17.9%)\n",
            "\n",
            "Example fails:\n",
            "0.2 Heading to San Francisco\n",
            "0.6 Heading to Chesapeake\n",
            "\n",
            "----\n",
            "0.2 is in San Francisco at Bay to Breakers.\n",
            "0.6 is in Irvine at Bay to Breakers.\n",
            "0.5 is in Fort Worth at Bay to Breakers.\n",
            "\n",
            "----\n",
            "0.5 Rocawear Heads to China, Building 300 Stores  - http://tinyurl.com/nofet3\n",
            "0.6 Rocawear Heads to Morocco, Building 300 Stores  - http://tinyurl.com/nofet3\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Add Typos\n",
            "Test cases:      498\n",
            "Fails (rate):    32 (6.4%)\n",
            "\n",
            "Example fails:\n",
            "0.9 San Francisco today.  Any suggestions?\n",
            "0.4 San Francisco today.  An ysuggestions?\n",
            "\n",
            "----\n",
            "0.6 I hope the girl at work  buys my Kindle2\n",
            "0.5 I hope the igrl at work  buys my Kindle2\n",
            "\n",
            "----\n",
            "0.1 Oooooooh... North Korea is in troubleeeee! http://bit.ly/19epAH\n",
            "1.0 Oooooooh... North Korea is in torubleeeee! http://bit.ly/19epAH\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Add 2 Typos\n",
            "Test cases:      498\n",
            "Fails (rate):    52 (10.4%)\n",
            "\n",
            "Example fails:\n",
            "0.4 Today is a good day to dislike AT&amp;T. Vote out of office indeed, @danielpunkass\n",
            "0.8 Today is a good day to dislik eAT&amp;T. Vote out of office indeed, @danieplunkass\n",
            "\n",
            "----\n",
            "0.0 i am furious with time warner and their phone promotions!\n",
            "1.0 i amf urious wiht time warner and their phone promotions!\n",
            "\n",
            "----\n",
            "0.4 @sekseemess no. I'm not itchy for now. Maybe later, lol.\n",
            "0.7 @seskeemess no. I'm not itchy for now. Mabye later, lol.\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Punctuation\n",
            "Test cases:      498\n",
            "Fails (rate):    23 (4.6%)\n",
            "\n",
            "Example fails:\n",
            "0.3 Only one exam left, and i am so happy for it :D\n",
            "0.5 Only one exam left, and i am so happy for it\n",
            "\n",
            "----\n",
            "0.5 Off to the bank to get my new visa platinum card\n",
            "0.4 Off to the bank to get my new visa platinum card.\n",
            "\n",
            "----\n",
            "0.6 testing Twitter API\n",
            "0.4 testing Twitter API.\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "Contractions\n",
            "Test cases:      103\n",
            "Fails (rate):    3 (2.9%)\n",
            "\n",
            "Example fails:\n",
            "0.3 @crlane I have the Kindle2. I've seen pictures of the DX, but haven't seen it in person. I love my Kindle - I'm on it everyday.\n",
            "0.6 @crlane I have the Kindle2. I have seen pictures of the DX, but have not seen it in person. I love my Kindle - I am on it everyday.\n",
            "\n",
            "----\n",
            "0.5 @ims What is AT&amp;T fucking up?\n",
            "0.6 @ims What's AT&amp;T fucking up?\n",
            "\n",
            "----\n",
            "0.5 @spinuzzi: Has been a bit crazy, with steep learning curve, but LyX is really good for long docs. For anything shorter, it would be insane.\n",
            "0.6 @spinuzzi: Has been a bit crazy, with steep learning curve, but LyX is really good for long docs. For anything shorter, it'd be insane.\n",
            "\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Negation\n",
            "\n",
            "simple negations: negative\n",
            "Test cases:      400\n",
            "Fails (rate):    73 (18.2%)\n",
            "\n",
            "Example fails:\n",
            "0.3 This is not a terrible translation.\n",
            "----\n",
            "0.4 This is not a terrible development.\n",
            "----\n",
            "0.5 This is not a horrible translation.\n",
            "----\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}